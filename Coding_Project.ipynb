{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Title: Evaluating the Performance of Different Machine Learning Models for Breast Cancer Diagnosis**\n",
        "\n"
      ],
      "metadata": {
        "id": "3Vl6E2zP8ZKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Libraries**\n",
        "Load the required libraries for data manipulation, preprocessing, visualization, and modeling."
      ],
      "metadata": {
        "id": "r2x39TNQQ-3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.optimizers import Adam as adam\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "3WryMUmytP-m"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load and Explore the Dataset**\n",
        "We will use the Breast Cancer Dataset (UCI Machine Learning Repository)."
      ],
      "metadata": {
        "id": "DyOlV6tTRKnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Overview**\n",
        "\n",
        "The dataset contains features computed from digitized images of fine needle aspirate (FNA) tests on breast masses.\n",
        "\n",
        "**Key Features:**\n",
        "Attributes like clump thickness, uniformity of cell size/shape, mitoses, etc.\n",
        "\n",
        "**Dataset size:** 699 samples, with some missing values in the attribute 'Bare Nuclei.'\n",
        "\n",
        "**Columns:**\n",
        "Sample code number (ID, not useful)\n",
        "\n",
        "Clump Thickness, Uniformity of Cell Size, ..., Bland Chromatin, etc. (features)\n",
        "\n",
        "**Target Variable:**\n",
        "Class (2 = benign, 4 = malignant)."
      ],
      "metadata": {
        "id": "iOi2ef6wRM9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data(url):\n",
        "    \"\"\"\n",
        "    Function to load and Displays the first few rows, data types, missing values, and summary statistics.\n",
        "\n",
        "    Parameters:\n",
        "        url (str): URL of the dataset.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Loaded dataset as a pandas DataFrame.\n",
        "    \"\"\"\n",
        "    # Column names for the dataset\n",
        "    column_names = [\n",
        "        'ID', 'Clump_Thickness', 'Uniformity_Cell_Size', 'Uniformity_Cell_Shape',\n",
        "        'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei',\n",
        "        'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses', 'Class'\n",
        "    ]\n",
        "\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv(url, names=column_names, header=None)\n",
        "    display(data)\n",
        "\n",
        "    # Replace '?' with NaN in the entire DataFrame before converting to numeric\n",
        "    data = data.replace('?', np.nan)\n",
        "\n",
        "    # Check for missing values and data types\n",
        "    print(\"\\nDataset Info:\")\n",
        "    print(data.info())\n",
        "\n",
        "    return data\n",
        "\n",
        "# URL of the dataset (UCI Breast Cancer Wisconsin Dataset)\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\"\n",
        "\n",
        "# Call the function\n",
        "data = load_and_preprocess_data(url)"
      ],
      "metadata": {
        "id": "n_4_HcS2RIaD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 808
        },
        "outputId": "acebc8e9-63d6-47f0-bea2-9b55beb8755c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistics on DataFrame\n",
        "# Mean, Median, Standard Deviation etc\n",
        "def major_statistics():\n",
        "\n",
        "    # mean and median:\n",
        "    mean_value = data.mean(numeric_only=True)\n",
        "    median_value = data.median(numeric_only=True)\n",
        "\n",
        "    # standard deviation\n",
        "    std_deviation = data.std(numeric_only=True)\n",
        "\n",
        "    skewness = data.skew(numeric_only=True)\n",
        "    kurtosis = data.kurt(numeric_only=True)\n",
        "\n",
        "    print(\"\\033[1mMean:\\n\\033[0m\", mean_value)\n",
        "    print(\"\\n\\033[1mMedian:\\n\\033[0m\", median_value)\n",
        "    print(\"\\n\\033[1mStandard Deviation:\\n\\033[0m\", std_deviation)\n",
        "    print(\"\\n\\033[1mSkewness:\\n\\033[0m\", skewness)\n",
        "    print(\"\\n\\033[1mKurtosis:\\n\\033[0m\", kurtosis)\n",
        "    return\n",
        "\n",
        "# Call the function\n",
        "major_statistics()"
      ],
      "metadata": {
        "id": "3mW0dIAtSF8p"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Preprocessing**\n",
        "Preprocessing ensures data is clean and ready for modeling. Steps include:\n",
        "1. Dropping unnecessary columns (e.g., 'ID').\n",
        "2. Handling missing values in the 'Bare Nuclei' column using median imputation.\n",
        "3. Encoding the target variable ('Class') as binary (0 = benign, 1 = malignant).\n",
        "4. Scaling features to standardize input for ANN and improve model convergence.\n",
        "\n",
        "#### Why Scaling?\n",
        "ANNs are sensitive to feature magnitudes. Standardizing features (mean = 0, std = 1) ensures faster convergence and better performance.\n"
      ],
      "metadata": {
        "id": "GbL4BCe9STdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(data):\n",
        "    \"\"\"\n",
        "    Preprocess the dataset.\n",
        "    - Handles missing values in 'Bare Nuclei'.\n",
        "    - Converts 'Class' to binary format (2 -> 0, 4 -> 1).\n",
        "    - Splits the data into training and testing sets.\n",
        "    - Normalizes the features using StandardScaler.\n",
        "\n",
        "    Args:\n",
        "        data: Loaded dataset as a pandas DataFrame.\n",
        "\n",
        "    Returns:\n",
        "        X_train_scaled, X_test_scaled, y_train, y_test: Normalized feature data and target labels.\n",
        "    \"\"\"\n",
        "    # Handle missing values in 'Bare Nuclei' by converting to numeric and filling missing values with median\n",
        "    # Convert '?' to NaN before applying pd.to_numeric\n",
        "    data['Bare_Nuclei'] = data['Bare_Nuclei'].replace('?', np.nan) # Replace '?' with NaN\n",
        "    data['Bare_Nuclei'] = pd.to_numeric(data['Bare_Nuclei'], errors='coerce')\n",
        "    median_value = data['Bare_Nuclei'].median()\n",
        "    data['Bare_Nuclei'] = data['Bare_Nuclei'].fillna(median_value)\n",
        "\n",
        "    # Verify missing values are handled\n",
        "    print(\"\\nMissing values after handling:\")\n",
        "    print(data.isnull().sum())\n",
        "\n",
        "    # Convert 'Class' to binary format\n",
        "    data['Class'] = data['Class'].replace({2: 0, 4: 1})\n",
        "    print(\"\\nTarget Variable Encoding Completed.\")\n",
        "\n",
        "    # Split features and target variable\n",
        "    X = data.drop(columns=['Class'])\n",
        "    y = data['Class']\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "    # Display shapes of training and testing data\n",
        "    print(\"\\nData split into training and test sets.\")\n",
        "    print(f\"Training Data Shape: {X_train.shape}\")\n",
        "    print(f\"Test Data Shape: {X_test.shape}\")\n",
        "\n",
        "    # Normalize the features using StandardScaler\n",
        "    # This ensures all features have a mean of 0 and a standard deviation of 1,\n",
        "    # which helps models (especially ANNs) converge faster and improve performance.\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Display a preview of the scaled data\n",
        "    print(\"\\nPreview of Scaled Features (Training Data):\")\n",
        "    print(pd.DataFrame(X_train_scaled).head())\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test, X_train\n",
        "\n",
        "# Call preprocess_data to create X_train, X_test, y_train, y_test\n",
        "X_train_scaled, X_test_scaled, y_train, y_test , X_train = preprocess_data(data)\n"
      ],
      "metadata": {
        "id": "ETs_wlhBl7Gt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6694619-aca2-4ff4-b750-4cb43a6075f3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Display Preprocessing Summary**"
      ],
      "metadata": {
        "id": "5yJhfrELSfIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display preprocessing summary\n",
        "print(\"\\nPreprocessing Summary\")\n",
        "print(\"----------------------\")\n",
        "print(\"Target variable encoded (4 → 1, 2 → 0).\")\n",
        "print(\"Data split into training and test sets.\")\n",
        "print(\"Data scaled using StandardScaler.\")\n",
        "print()\n",
        "print(f\"Training Data Shape: {X_train_scaled.shape}\")\n",
        "print(f\"Test Data Shape: {X_test_scaled.shape}\")\n",
        "print(f\"Training Target Shape: {y_train.shape}\")\n",
        "print(f\"Test Target Shape: {y_test.shape}\")\n",
        "print(\"----------------------\")\n",
        "print(\"Class Distribution in Training Data:\")\n",
        "print(y_train.value_counts())\n",
        "print()\n",
        "print(\"Class Distribution in Test Data:\")\n",
        "print(y_test.value_counts())\n"
      ],
      "metadata": {
        "id": "-tibV6u2n9dp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf52eba8-90fa-4bfc-bca3-4813e00afeda"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualize Class Distribution**\n",
        "This step visualizes the class distribution (Benign vs Malignant) to ensure the dataset is balanced."
      ],
      "metadata": {
        "id": "_qW79-KCSt-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_class_distribution(data, target_column):\n",
        "    \"\"\"\n",
        "    Visualize the class distribution for the target variable.\n",
        "    \"\"\"\n",
        "    print(\"\\nClass Distribution:\")\n",
        "    print(data[target_column].value_counts())\n",
        "\n",
        "    # Plot class distribution\n",
        "    sns.countplot(x=target_column, data=data)\n",
        "    plt.title(\"Class Distribution: Benign (0) vs Malignant (1)\" , fontsize=14)\n",
        "    plt.xlabel(\"Class\" , fontsize=14)\n",
        "    plt.ylabel(\"Count\" , fontsize-14)\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "# Call the function with the correct target column name 'Class'\n",
        "visualize_class_distribution(data, 'Class')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "U7f98XWySyxJ",
        "outputId": "0b3349c8-834c-4715-d379-27dba88b2287"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pie Plot**"
      ],
      "metadata": {
        "id": "zuH65rKhS8Mv"
      }
    }
    {
      "cell_type": "code",
      "source": [
        "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
        "labels = 'Benign', 'Malignant'\n",
        "sizes = [458, 241]  # Count of benign and malignant samples\n",
        "explode = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Malignant')\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "\n",
        "plt.title('Class Distribution in Dataset')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Km3OnkRiS9Mv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Modeling**\n",
        "### **Decision Tree**\n",
        "Build and train a Decision Tree classifier on the training data."
      ],
      "metadata": {
        "id": "wGn1rH-fS-Mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_and_train_decision_tree(X_train, y_train):\n",
        "    \"\"\"\n",
        "    Build and train a Decision Tree classifier.\n",
        "\n",
        "    Args:\n",
        "        X_train: Training feature data as a numpy array.\n",
        "        y_train: Training target labels as a numpy array.\n",
        "\n",
        "    Returns:\n",
        "        DecisionTreeClassifier: Trained classifier.\n",
        "    \"\"\"\n",
        "    # Instantiate the Decision Tree classifier\n",
        "    dt_classifier = DecisionTreeClassifier()\n",
        "\n",
        "    # Train the classifier on the training data\n",
        "    dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "    return dt_classifier\n",
        "\n",
        "# Build and train the Decision Tree classifier\n",
        "dt_classifier = build_and_train_decision_tree(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "5H5H2rXES_mR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluate Decision Tree**\n",
        "Evaluate the performance of the Decision Tree classifier on the test data."
      ],
      "metadata": {
        "id": "yBmTBi6CS-Lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classifier(classifier, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Evaluate a classifier's performance.\n",
        "\n",
        "    Args:\n",
        "        classifier: The trained classifier.\n",
        "        X_test: Test feature data as a numpy array.\n",
        "        y_test: Test target labels as a numpy array.\n",
        "\n",
        "    Returns:\n",
        "        float: Accuracy of the classifier.\n",
        "        str: Classification report.\n",
        "        np.array: Confusion matrix.\n",
        "    \"\"\"\n",
        "    # Make predictions on the test data\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    # Calculate the accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Generate a classification report\n",
        "    class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "    # Generate the confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    return accuracy, class_report, conf_matrix\n",
        "\n",
        "# Evaluate the Decision Tree classifier\n",
        "dt_accuracy, dt_class_report, dt_conf_matrix = evaluate_classifier(dt_classifier, X_test_scaled, y_test)\n",
        "\n",
        "print(\"Accuracy of Decision Tree: {:.2f}%\".format(dt_accuracy * 100))\n",
        "print(\"\\nClassification Report:\\n\", dt_class_report)\n",
        "print(\"\\nConfusion Matrix:\\n\", dt_conf_matrix)"
      ],
      "metadata": {
        "id": "fOjBm7vcS-Md"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Random Forest**\n",
        "Build and train a Random Forest classifier."
      ],
      "metadata": {
        "id": "JcW2iF-SLkio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_and_train_random_forest(X_train, y_train):\n",
        "    \"\"\"\n",
        "    Build and train a Random Forest classifier.\n",
        "\n",
        "    Args:\n",
        "        X_train: Training feature data as a numpy array.\n",
        "        y_train: Training target labels as a numpy array.\n",
        "\n",
        "    Returns:\n",
        "        RandomForestClassifier: Trained classifier.\n",
        "    \"\"\"\n",
        "    # Instantiate the Random Forest classifier\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "    # Train the classifier on the training data\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    return rf_classifier\n",
        "\n",
        "# Build and train the Random Forest classifier\n",
        "rf_classifier = build_and_train_random_forest(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "NxaYeiZHLkik"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluate Random Forest**\n",
        "Evaluate the performance of the Random Forest classifier on the test data."
      ],
      "metadata": {
        "id": "nBSoX-pSLlDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Random Forest classifier\n",
        "rf_accuracy, rf_class_report, rf_conf_matrix = evaluate_classifier(rf_classifier, X_test_scaled, y_test)\n",
        "\n",
        "print(\"Accuracy of Random Forest: {:.2f}%\".format(rf_accuracy * 100))\n",
        "print(\"\\nClassification Report:\\n\", rf_class_report)\n",
        "print(\"\\nConfusion Matrix:\\n\", rf_conf_matrix)"
      ],
      "metadata": {
        "id": "Qx4UCuBSLkhy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Artificial Neural Network (ANN)**\n",
        "Build and train an Artificial Neural Network for classification."
      ],
      "metadata": {
        "id": "M4S7gpNdLkij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_and_train_ann(X_train, y_train):\n",
        "    \"\"\"\n",
        "    Build and train an Artificial Neural Network.\n",
        "\n",
        "   

  
